---
title: "tp2"
author: "Lapu Matthias | Amaël Kreis"
date: "2023-02-17"
output: 
  pdf_document: 
    latex_engine: xelatex
---

## I. Variation sous-jacente et échantillonnage répété

1.  Si X ∼ E(0.5), quelle est la probabilité qu'on observe une valeur supérieure à 3?

2.Simulez un échantillon de taille n = 20 d'un loi de E(0,5), créez un histogramme de votre échantillon et commentez la forme de votre histogramme. Superposer la vrai densité. Quelle est la probabilité empirique qu'on observe une valeur supérieure à 3 ?

```{r}
x<-rexp(20,0.5)
hist(x, freq=FALSE)
maxvalue <- ceiling(max(x))
lines(0:maxvalue,dexp(0:maxvalue, 0.5), col="green",)
```

Commentaire histogramme à insérer

3.Répétez cette opération 5 ou 6 fois et commentez les différences entre les histogrammes que vous obtenez à chaque fois. Utilisez la même limite sur les axes pour faciliter la comparaison. Notez également comment la probabilité empirique qu'on observe une valeur supérieure à 3 change.

```{r}

```

4.  Augmentez la taille de votre échantillon à 100 et répétez votre expérience. Que remarquez-vous?

```{r, echo=FALSE}
x<-rexp(100,0.5)
hist(x, freq=FALSE)
maxvalue <- ceiling(max(x));
lines(0:maxvalue,dexp(0:maxvalue, 0.5), col="blue",)
```

## II. Variabilité aléatoire du maximum de l'échantillon

1. Simuler un échantillon de taille n = 10 d'une loi U(−1, 1) et enregistrez le maximum de l'échantillon.

```{r}
x <- runif(10, -1, 1)
max <- max(x)
```

2. Répétez les deux étapes ci-dessus dix fois, en écrivant le maximum de l'échantillon à chaque fois. Commentez la variabilité des valeurs que vous obtenez pour les maxima de votre échantillon.

```{r}
for (i in 1:10) {
  x <- runif(10, -1, 1)
}
```

3. Répétez 100 fois et construisez un histogramme et une boîte à moustaches. Quelle est la loi dumaximum, M = max 1≤i≤n X i où X i ∼ U(−1, 1) (TD1) ? Superposer la densité théoreique sur l'histogramme. Que remarquez-vous ?

```{r}
par(mfrow=c(3,4))
for (i in 1:100) {
  x <- runif(10, -1, 1)
  hist(x)
  boxplot(x, horizontal = TRUE)
}
```

4. Augmentez la taille de votre échantillon à 50 et répétez votre expérience. Que remarquez-vous? Sont-ils proches de la symétrie ?

```{r}
x <- runif(50, -1, 1)
```

# Monte Carlo Methods

## Moyenne et phénomène de concentration.

1.  Supposons que la variance σ2 = V [ψ(X)] \< ∞. Donner une borne de cette quantité en utilisant l'inégalité de Bienaymé Chebychev.

On trouve grace à l'inégalité de Bienaymé Chebychev:

$$

a^{2}P(|\psi(X) - \theta| \ge a) \le V[\psi(X)]

$$

2\. En supposant que a ≤ ψ(Xi) ≤ b, donner une borne en utilisant l'inégalité de Hoeffding.

Posons : 
$$
S_{n} = \sum_{k=1}^n \psi(X_k)
$$
D'après l'énoncé, nous savons que :
$$
\frac{1}{n} \sum_{i=1}^n \psi(X_i) = \hat{\theta}
$$
Ainsi : 
$$
\frac{S_n}{n} = \hat{\theta} 
$$
Donc :
$$
S_n=n\hat{\theta}
$$


D'après l'inégalité de Hoeffding nous savons que : 
$$
P(|S_n - E(S_n)| \geq t) \leq 2exp(\frac{-2t²}{\sum_{k=1}^n (b_k-a_k)²})
$$

Calculons l'esperance de S_n:
$$
E(S_n) = E(\sum_{k=1}^n \psi(X_k)) = \sum_{k=1}^n E(\psi(X_k)) = \sum_{k=1}^n \theta = n\theta
$$
Ainsi :
$$
P(|n\hat{\theta} - n\theta| \geq t) \leq 2exp(\frac{-2t²}{\sum_{k=1}^n (b_k-a_k)²})
\\
P(|\hat{\theta} - \theta| \geq \frac{t}{n}) \leq 2exp(\frac{-2t²}{\sum_{k=1}^n (b_k-a_k)²})
$$
On pose : 
$$
\frac{t}{n} = \delta
\\
P(|\hat{\theta} - \theta| \geq \delta) \leq 2exp(\frac{-(2n\delta)²}{\sum_{k=1}^n (b_k-a_k)²})
$$
3\. De combien d'échantillons auriez-vous besoin pour que la probabilité que \delta  = 2\phi soit inférieur à 1%.

## Application pour l'estimation de probabilité 

1\. Pour la question 1 avec \epsilon(0.5) identifier le paramètre d'intéret \theta et donner un estimateur de \hat{\theta}

Le paramètre d'intérêt est la moyenne de la fonction exponentielle, c'est à dire 2 pour \epsilon(0.5)

Un estimateur \hat{\theta} de la fonction serait : 
$$
E(\epsilon(\theta)) = \frac{1}{\theta}
\\
\bar{X_n} = \frac{1}{n} \sum_{i=1}^{n} X_i
\\
\hat{\theta_n} = \frac{1}{\bar{X_n}}
$$
La moyenne empirique tend presque surement vers la moyenne , ainsi l'estimateur est donc consistant.
Il faut ensuite utiliser l'inégalité de Hoeffding.

L'énoncé demande à ce que E(Z) = garantie probabiliste de l'erreur. Il faut trouver Z .

## Théorème Central Limite et Estimation Monte Carlo

1\. Vérifier que l'espérance théorique d'une loi de Pareto est E [X] = αa/α−1.

$$
P(X\le t)= (1-\left( \frac{a}{t} \right)^{\alpha}) , \;avec \;x \ge a
$$

Donc : 

ERROR LATEX
$$

E(X) = \int_0^{+\infty} 1-P(X \le t)dt 
\\
= \int_0^\infty P(X \gt t)dt
\\
=  a+a^{\alpha}\int_a^{+\infty}\frac{1}{t^{\alpha}}dt=a + \frac{a}{\alpha -1} =\frac{\alpha a}{\alpha -1}
$$


2\. Simuler N = 1000 échantillons i.i.d de loi commune Pareto P(a, α) (avec votre choix de paramètres)

de taille n = 5, 30, 100 et calculer les moyennes et variances empiriques ¯Xn,i et Sn,i, i = 1, . . . ,N.

```{r echantillons,echo=FALSE}
s<-library("EnvStats")
#vars
N <- 1000
a <- 1
alpha <- 3
#creation des echantillons
ech5 <- matrix(NA,5,1000) #echantillon de taille 5
for (i in seq(5)) {
  ech5[i,] <- rpareto(N,a,alpha)
}
ech30 <- matrix(NA,30,1000) #echantillon de taille 30
for (i in seq(30)) {
  ech30[i,] <- rpareto(N,a,alpha)
}
ech100 <- matrix(NA,100,1000)  #echantillon de taille 100
for (i in seq(100)) {
  ech100[i,] <- rpareto(N,a,alpha)
}
print("Moyenne empirique n = 5")
moy5 <- rowMeans(ech5)
print(moy5)
print("Moyenne empirique n = 30")
moy30 <- rowMeans(ech30)
print(moy30)
print("Moyenne empirique n = 100")
moy100 <- rowMeans(ech100)
print(moy100)
print("Variance empirique n = 5")
print(moy5^2/1000)
print("Variance empirique n = 30")
print(moy30^2/1000)
print("Variance empirique n = 100")
print(moy100^2/1000)
hist(moy5)
hist(moy30,breaks = 10)
hist(moy100,breaks = 20)
```

4.  A l'aide d'une renormalisation adéquate (an, bn), montrer que Un,i = ¯Xn,i−an/ bn a une loi que vous pouvez approchez. Comparez histogramme de les moyennes empiriques normalisées, Un,i, et distribution théorique approchée. Quelle est l'influence de la taille de l'échantillon n sur la qualité de cette approximation?

```{r normalisation, }
moy5CentreeReduite <- (moy5-mean(moy5))/mean(moy5^2/1000)
moy30CentreeReduite <- (moy30-mean(moy30))/mean(moy30^2/1000)
moy100CentreeReduite <- (moy100-mean(moy100))/mean(moy100^2/1000)

hist(moy5CentreeReduite)
lines(seq(-50,50,by=0.1),dpareto(seq(-50,50,by=0.1),1,3),col = "blue")
hist(moy30CentreeReduite,breaks = 10)
lines(seq(-50,50,by=0.1),dpareto(seq(-50,50,by=0.1),1,3),col = "blue")
hist(moy100CentreeReduite,breaks = 20)
lines(seq(-50,50,by=0.1),dpareto(seq(-50,50,by=0.1),1,3),col = "blue")
```

## Quand le théorème de central limite ne s'applique pas

1\. Simuler un échantillon de taille n = 20 d'une loi de C(2) et calculer la moyenne empirique ¯Xn.

Moyenne empirique:

```{r, echo=FALSE}
print(mean(rcauchy(20,2,1)))
```

2\. Faites varier la taille de l'échantillon n = 20, 100, 1000 et 10000. Qu'en déduire ?

```{r,echo=FALSE}
print(mean(rcauchy(20,2,1)))
print(mean(rcauchy(100,2,1)))
print(mean(rcauchy(1000,2,1)))
print(mean(rcauchy(10000,2,1)))
```
On remarque que malgré le nombre élévé de l'échantillon la moyenne ne semble pas se stabiliser comme pour une loi normale.

3\. Expliquer ce comportement

Nous savons d'après le cours de probabilités que la loi de cauchy n'admet pas d'espérance ni d'écart type. Cela explique donc le comportement de la moyenne malgré la taille de l'échantillon.

4\. Quelle est la médiane d'une loi de cauchy ?

La courbe est symétrique ,    la médiane d'une loi de cauchy est son paramètre. 

$$
f(x,\theta) = \frac{1}{\pi} \frac{1}{1 + (x-\theta)²}
\\
\frac{1}{2} = \frac{1}{\pi} \int_{-a}^{a} \frac{dx}{1+(x-\theta)²}
\\
F^{-1} (\frac{1}{2}) = \theta
$$

5\. En déduire un estimateur de theta et evaluer la performance de cet estimateur sur les différents échantillons.

Nous pouvons essayer d'approximer \theta , c'est-à-dire la médiane, cela revient donc à chercher une estimation du quantile en 0.5 . D'après le cours, les quantiles permettent de localiser les valeurs les plus fréquentes. Nous allons donc essayer d'estimer le quantile 
Utilisons un échantillon (X_1,X_2,...,X_n) de loi C(\theta)

Idée : Prendre la médiane des echantillons X_(1/2) ? Parait bizarre

```{r}
print(qcauchy(0.5))
```